{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#演示 PydanticOutputParser 的用法",
   "id": "4be4d07648044301"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T13:13:52.849602Z",
     "start_time": "2025-08-20T13:13:52.264032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "cd4a4f055613750",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5:7b-instruct\",\n",
    "    temperature=0,\n",
    ")\n",
    "# llm=ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite',temperature=0)\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: int = Field(description=\"person's age\")\n",
    "    occupation: str = Field(description=\"person's job\")\n",
    "\n",
    "class People(BaseModel):\n",
    "    people: list[Person] = Field(description=\"list of people\")\n",
    "\n",
    "# 创建解析器\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# 创建带格式说明的提示\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract information about people from the following text.\"),\n",
    "    (\"human\", \"{text}\"),\n",
    "    (\"human\", \"{format_instructions}\")\n",
    "])\n",
    "\n",
    "# 完整链\n",
    "chain = (\n",
    "    {\"text\": RunnablePassthrough(), \"format_instructions\": lambda _: parser.get_format_instructions()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"Alice is 30 years old and works as a doctor. Bob is 25 and is an engineer.\")\n",
    "print(result)"
   ],
   "id": "574cced6b519890e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#演示StrOutputParser",
   "id": "ac709d29c3d4ead0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def demo_str_output_parser():\n",
    "    # llm=ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite',temperature=0)\n",
    "    llm = ChatOllama(\n",
    "        model=\"qwen2.5:7b-instruct\",\n",
    "        temperature=0,    )\n",
    "    \"\"\"演示 StrOutputParser 的使用\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📝 StrOutputParser 演示\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # StrOutputParser 是最基础的解析器，直接返回 LLM 的文本输出\n",
    "    str_parser = StrOutputParser()\n",
    "\n",
    "    # 基础用法\n",
    "    prompt = ChatPromptTemplate.from_template(\"写一首关于{topic}的短诗\")\n",
    "\n",
    "    # 构建链\n",
    "    chain = prompt | llm | str_parser\n",
    "\n",
    "    result = chain.invoke({\"topic\": \"春天\"})\n",
    "    print(f\"🎨 诗歌结果:\\n{result}\")\n",
    "    print()\n",
    "demo_str_output_parser()"
   ],
   "id": "4891f2be6877f0b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#演示并行处理",
   "id": "46898cf348fa3edb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T13:17:00.640435Z",
     "start_time": "2025-08-20T13:16:56.705901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# llm = ChatOllama(\n",
    "#     model=\"qwen2.5:7b-instruct\",\n",
    "#     temperature=0,\n",
    "# )\n",
    "llm=ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite',temperature=0)\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "str_parser = StrOutputParser()\n",
    "# 并行处理多个任务\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"summary\": ChatPromptTemplate.from_template(\"Summarize: {text}\") | llm | str_parser,\n",
    "    \"keywords\": ChatPromptTemplate.from_template(\"Extract keywords from: {text}\") | llm | str_parser,\n",
    "    \"sentiment\": ChatPromptTemplate.from_template(\"Analyze sentiment of: {text}\") | llm | str_parser\n",
    "})\n",
    "\n",
    "results = parallel_chain.invoke({\"text\": \"I love this new AI technology!\"})\n",
    "print(results)"
   ],
   "id": "7f5dd67229d420dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'This is a very short and enthusiastic statement expressing strong positive feelings about a new AI technology.', 'keywords': 'Here are the keywords extracted from \"I love this new AI technology!\":\\n\\n*   **AI**\\n*   **technology**\\n*   **new**\\n*   **love**', 'sentiment': 'The sentiment of the sentence \"I love this new AI technology!\" is overwhelmingly **positive**.\\n\\nHere\\'s a breakdown of why:\\n\\n*   **\"love\"**: This is a very strong positive emotion word. It indicates deep affection, enjoyment, and approval.\\n*   **\"this new AI technology\"**: This phrase identifies the object of the positive sentiment. The use of \"new\" can sometimes imply excitement or anticipation, which further contributes to the positive tone.\\n\\nTherefore, the sentiment is clearly **positive**.'}\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
